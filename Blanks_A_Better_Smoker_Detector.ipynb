{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKzBo_NmCSMR"
      },
      "source": [
        "\n",
        "## Case Study: A better Smoker Detector\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "In this notebook, you will work on the insurance csv file. Your goal is not only to make a prediction, it is to make a prediction with the best possible way. So you will be building, evaluating, and improving your model.\n",
        "\n",
        "\n",
        "## Dataset Description\n",
        "\n",
        "\n",
        "*   **age**: age of primary beneficiary\n",
        "*   **sex**: insurance contractor gender, female, male\n",
        "*   **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
        "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
        "*   **children**: Number of children covered by health insurance / Number of dependents\n",
        "*   **smoker**: Smoking\n",
        "*   **region**: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
        "*   **charges**: Individual medical costs billed by health insurance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW2QzRbXR5Ph"
      },
      "source": [
        "Our problem would be to predict if a person is smoker or not based on all the other features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k7QqVknG5ya"
      },
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfyJQMOnE_48"
      },
      "source": [
        "#### Import necessary python modules\n",
        "\n",
        "We will need the following libraries:\n",
        " - Numpy — for scientific computing (e.g., linear algebra (vectors & matrices)).\n",
        " - Pandas — providing high-performance, easy-to-use data reading, manipulation, and analysis.\n",
        " - Matplotlib — plotting & visualization.\n",
        " - scikit-learn — a tool for data mining and machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9nnDKPjAfGq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LEivAvUHIE3"
      },
      "source": [
        "#### Read & visualize data\n",
        "Let's load the **insurance.csv** dataset to our code, using **pandas** module, more specifically, the **read_csv** function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hep8239AzVU"
      },
      "source": [
        "# read CSV file in Pandas\n",
        "data = pd.read_csv('insurance.csv')\n",
        "\n",
        "# display first 5 rows\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgIxvmAKhiqe"
      },
      "source": [
        "## 2. Exploratory Data Analysis\n",
        "\n",
        "Let's dig deeper & understand our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbXDTkiQhzwq"
      },
      "source": [
        "**Question 1:** how many rows & columns in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUf0K_SMh1og"
      },
      "source": [
        "# get the number of rows and columns\n",
        "rows =\n",
        "columns =\n",
        "\n",
        "print('There are {} rows and {} columns.'.format(rows,columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPqsS9S2B2M4"
      },
      "source": [
        "Using the function **info()**, we can check:\n",
        " - data types (int, float, or object (e.g., string))\n",
        " - missing values\n",
        " - memory usage\n",
        " - number of rows and columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exWsHvXSA7nz"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt2KsZa2B63T"
      },
      "source": [
        "Using the function **describe()**, we can check the mean, standard deviation, maximum, and minimum of each numerical feature (column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pifR8QwkA-DW"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C6DoqLJkZaJ"
      },
      "source": [
        "#### Data Imbalance Checking\n",
        "\n",
        "First, let's see how many smokers vs non-smokers we have."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2:** Select the instances where the data.smoker == \"yes\" and the ones where the data.smoker == \"no\". Save them in smokers and non_smokers dataframes respectively. Then count how many you have in each category."
      ],
      "metadata": {
        "id": "nJZ1MmceijJr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bYxq0B4m4eg"
      },
      "source": [
        "# select smokers\n",
        "smokers =\n",
        "\n",
        "# select non smokers\n",
        "non_smokers =\n",
        "\n",
        "print('There are {} smokers and {} non-smokers.'.format(smokers.shape[0], non_smokers.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3:** Is your data balanced?"
      ],
      "metadata": {
        "id": "ZndHFJ-9i9h8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bajf4fhFleUX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knOEySxYaOwJ"
      },
      "source": [
        "###Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzGzI6TbaSbB"
      },
      "source": [
        "Let's start by seeing how much each feature tells us about a person being  a smoker or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "albiV9oTXWye"
      },
      "source": [
        "numerical_features = ['charges', 'bmi', 'age', 'children']\n",
        "\n",
        "subplot_number = 421\n",
        "fig = plt.figure(figsize=(10,15))\n",
        "\n",
        "for f in numerical_features:\n",
        "\n",
        "  ax = fig.add_subplot(subplot_number)\n",
        "  subplot_number += 1\n",
        "  ax.hist(smokers[f])\n",
        "  ax.set_title('Distribution of ' + f + ' for smokers')\n",
        "\n",
        "  ax = fig.add_subplot(subplot_number)\n",
        "  subplot_number += 1\n",
        "  ax.hist(non_smokers[f])\n",
        "  ax.set_title('Distribution of '+ f + ' for non-smokers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** From the above histograms, deduce which feature tells us the most about a person being smoker or not?"
      ],
      "metadata": {
        "id": "OhSE6xoKjKd_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa8eagVZwLg"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gjS7Ss5aji3"
      },
      "source": [
        "Now let's see if the gender influences being a smoker or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defv0Lx4aqDy"
      },
      "source": [
        "Gender = pd.crosstab(data['sex'],data['smoker'])\n",
        "print(Gender)\n",
        "Gender.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5:** What can you conclude about the gender and the smoker status?"
      ],
      "metadata": {
        "id": "5s6hxMFhjWU4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PELhantCbEGV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3X3fDBXnX16"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "\"Garbage in, garbage out\".\n",
        "\n",
        "Data should be preprocessed and cleaned to get rid of noisy data.\n",
        "Preprocessing includes:\n",
        " - dealing with missing data\n",
        "   - remove whole rows (if they are not a lot)\n",
        "   - infer (e.g., date of birth & age)\n",
        "   - fill with mean, median, or even 0\n",
        " - removing unsued column(s)\n",
        " - convert categorical (non numerical) data into numerical\n",
        " - normalization: standarize data ranges for all features (e.g., between 0 and 1)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " Let's start by removing missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** How many missing value are there in each column?"
      ],
      "metadata": {
        "id": "V3nt2oUpjh70"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mslOEw7wmf_N"
      },
      "source": [
        "# print how many missing value in each column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's drop rows with missing values"
      ],
      "metadata": {
        "id": "4o1QZfHwjpmG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXvduiy1nckz"
      },
      "source": [
        "# drop rows with missing values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGcXlEP6ryIZ"
      },
      "source": [
        "#### Convert Categorical columns to numerical\n",
        "\n",
        "*   We need to convert the sex column from male/female to 0/1.\n",
        "*   We need to convert the smoker column from no/yes to 0/1.\n",
        "\n",
        "\n",
        "Let's start with the sex column\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7:**\n",
        "\n",
        "\n",
        "*   Replace male and female with 0 and 1\n",
        "*   Replace smoker and non smoker represented by yes and no in the dataframe with 0 and 1\n",
        "\n"
      ],
      "metadata": {
        "id": "b-hWWzyNjx8B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEbrz7HnfuY"
      },
      "source": [
        "# define dictionary\n",
        "\n",
        "\n",
        "# replace sex column with 0/1\n",
        "\n",
        "\n",
        "\n",
        "# print head to verify\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuX-fpHesgmi"
      },
      "source": [
        "And now the smokers column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfU8gCe7sCDS"
      },
      "source": [
        "# define dictionary\n",
        "smokers = {'no':0, 'yes':1}\n",
        "# replace smokers column with 0/1\n",
        "data['smoker'] = data['smoker'].apply(lambda x: smokers[x])\n",
        "# print head to verify\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovM89R-eYCi"
      },
      "source": [
        "And now the Region Column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug0gruFnebxI"
      },
      "source": [
        "# define dictionary\n",
        "regions = {'southwest':0, 'southeast':1, 'northwest':2, 'northeast':3}\n",
        "# replace region column with the corresponding values\n",
        "data['region'] = data['region'].apply(lambda x: regions[x])\n",
        "# print head to verify\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwfqKXYftiS-"
      },
      "source": [
        "#### Normalization\n",
        "\n",
        "**Question 7:** Let's scale all the columns by dividing by the maximum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJrBAhytsq8c"
      },
      "source": [
        "# get the max of each column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOxtgIjhu36f"
      },
      "source": [
        "# divide each column by its maximum value\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwQPUuGy8vmw"
      },
      "source": [
        "## 4. Model Training & Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTNYhHSpHezL"
      },
      "source": [
        "#### Data splits\n",
        "\n",
        "**Question 8:** Before training, we need to split data into training (80%) & testing (20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n3DqBUG892K"
      },
      "source": [
        "features = ['age',\t'sex',\t'bmi',\t'children', 'region',\t'charges']\n",
        "X = data[features]\n",
        "\n",
        "y = data['smoker']\n",
        "\n",
        "# split dataset in a 80/20 split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dPqqZiT97Eg"
      },
      "source": [
        "#### Logistic Regression Modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYUD8wNF9bm3"
      },
      "source": [
        "# define our regression model\n",
        "model = LogisticRegression()\n",
        "# train our model\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KIBXHUKHijy"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEhqbtbCHmg8"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy_model_1 = accuracy_score(y_pred, y_test)\n",
        "precision_model1 = precision_score(y_test, y_pred)\n",
        "recall_model1 = recall_score(y_test, y_pred)\n",
        "f1_score_model1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_model_1,\n",
        "      \"\\nPrecision:\",precision_model1,\n",
        "      \"\\nRecall:\", recall_model1,\n",
        "      \"\\nF1 Score:\", f1_score_model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTuXCuF4kJKX"
      },
      "source": [
        "We can see that the recall, and the f1 score can be improved."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9:** What can you do to improve results?"
      ],
      "metadata": {
        "id": "a-H44ncekdNv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvDITkSAj1GI"
      },
      "source": [
        "##5. Model Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEQegNwxkE4t"
      },
      "source": [
        "Now we will try to improve the model that we built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muAmLM-Hmpv0"
      },
      "source": [
        "####Handle data Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KMyylha2Y-g"
      },
      "source": [
        "data['smoker'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MzV8OJ5m03J"
      },
      "source": [
        "We can see that we have a clearly imbalanced dataset. To handle it, we choose to do 2 steps:\n",
        "* Oversampling the minority class with a factor of 0.5\n",
        "* Undersampling the majority class to obtain the same number in the 2 classes\n",
        "<br>\n",
        "We do that by using the RandomOverSaampler and RandomUnderSampler from the imblearn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ZRF4gMnjuf"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "over = RandomOverSampler(sampling_strategy= 0.5)\n",
        "x_new, y_new = over.fit_resample(X, y)\n",
        "under = RandomUnderSampler(sampling_strategy= 1)\n",
        "x_new, y_new = under.fit_resample(x_new, y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjVUHgi_ou-g"
      },
      "source": [
        "plt.hist(y_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_z-8P_io7GK"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6pV29t-pcFm"
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "\n",
        "accuracy_model2 = accuracy_score(y_test, y_pred)\n",
        "precision_model2 = precision_score(y_test, y_pred)\n",
        "recall_model2 = recall_score(y_test, y_pred)\n",
        "f1_score_model2 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_model2,\n",
        "      \"\\nPrecision:\",precision_model2,\n",
        "      \"\\nRecall:\", recall_model2,\n",
        "      \"\\nF1 Score:\", f1_score_model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDP6PNQUtzJZ"
      },
      "source": [
        "We can see how much our scores got better when we balanced our dataset."
      ]
    }
  ]
}