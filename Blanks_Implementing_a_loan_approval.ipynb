{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PuiYEDpYK-mm",
        "JGumTAZLK-mm",
        "oBpOQ6MVK-mr",
        "RpDPJgQzK-mu",
        "x90s4TXqK-mx",
        "p-aMmUFxK-m0",
        "T1jU9d28K-m4",
        "qjg5n5OfK-m8",
        "5qIDedqKTtfN",
        "xTy8UkrEUNLM"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elgDcjlyK-lQ"
      },
      "source": [
        "#Loan Approval\n",
        "\n",
        "---\n",
        "**Objective:**\n",
        "In this exercise, we will explore a dataset of Loan data with the below info. We will try later to predict the status of loan for individuals based the following information.</font>\n",
        "\n",
        "## DataSet Description\n",
        "\n",
        "- **Loan_ID:** data set unique ID <br>\n",
        "- **Gender:** individual gender<br>\n",
        "- **Married:** individual marital status<br>\n",
        "- **Dependents:** number of dependents<br>\n",
        "- **Education:** individual education status<br>\n",
        "- **Self_Employed:** individual employment status<br>\n",
        "- **ApplicantIncome:** individual income<br>\n",
        "- **CoapplicantIncome:** individual Coapplicant income<br>\n",
        "- **LoanAmount:** Loan amount in thousands<br>\n",
        "- **Loan_Amount_Term:** term of loan in months<br>\n",
        "- **Credit_History:** credit history meets guidelines<br>\n",
        "- **Property_Area:** Urban/ Semi Urban/ Rural<br>\n",
        "- **Loan_Status:** loan approved (Y/N)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIFhQSUBK-lS"
      },
      "source": [
        "# 1. Import necessary python modules (libraries)\n",
        "<br>\n",
        "We will need the following libraries:\n",
        "\n",
        "- Numpy — for scientific computing (e.g., linear algebra (vectors & matrices)).\n",
        "- Pandas — providing high-performance, easy-to-use data reading, manipulation, and analysis.\n",
        "- Matplotlib & seaborn — plotting & visualization.\n",
        "- scikit-learn — a tool for data mining and machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZwyPrVkK-lT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOjSBkYGeHga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xjXdDyTK-lW"
      },
      "source": [
        "# 2. Read & visualize data\n",
        "To load the data to our code, we use pandas module, more specifically, the read_csv function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use two datasets: the **train.csv** and **test.csv** files"
      ],
      "metadata": {
        "id": "IMas3ClTqP3R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4KVJodDK-lX"
      },
      "source": [
        "Combine the two dataset in order to apply the same preprocessing steps in both dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaN-1eM5K-lX"
      },
      "source": [
        "df_train=pd.read_csv('train.csv')\n",
        "df_test=pd.read_csv('test.csv')\n",
        "df=df_train.append(df_test)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKcAeoOVK-ld"
      },
      "source": [
        "# 4. Exploratory Data Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** Use the shape function to check the dimensions of your dataframe"
      ],
      "metadata": {
        "id": "UtN7MWS1rR0V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DmXe7W2K-ld"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVH8LAjLK-lg"
      },
      "source": [
        "##### Using the function info(), we can check:\n",
        "\n",
        "- data types (int, float, or object (e.g., string))\n",
        "- missing values\n",
        "- memory usage\n",
        "- number of rows and columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kesvYr2pK-lg"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2:** Which Columns contain Missing Values?"
      ],
      "metadata": {
        "id": "KVCIbYvarZoV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ15pJj2K-lj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ebzltrK-lj"
      },
      "source": [
        "##### Using the function describe(), we can check the following  values for each numerical feature (column)\n",
        "- mean\n",
        "- standard deviation\n",
        "- maximum\n",
        "- minimum\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECiIV49DK-lk"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3:** Which feature is not actually numerical and yet was included in the above statistical description?"
      ],
      "metadata": {
        "id": "cBOJZ8x9ru6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsmkavZQK-ln"
      },
      "source": [
        "Analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYPOBUMYK-ln"
      },
      "source": [
        "np.sort(df.Credit_History.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4:** Write the code to get unique values of the Loan_Amount_Term variable and sort the values"
      ],
      "metadata": {
        "id": "CZ9f7p_jsBXU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOBFeq9EK-lq"
      },
      "source": [
        "Loan_Amount_Term is a variable of numerical discrete data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdUjK1DPK-lq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove Na and create a density graph"
      ],
      "metadata": {
        "id": "vbY2IDDJqScF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GLVciuCK-l4"
      },
      "source": [
        "plt.figure(1)\n",
        "plt.subplot(121)\n",
        "removeNA_df=df.dropna() # we need to remove Na in order to plot a density graph\n",
        "sns.distplot(removeNA_df['LoanAmount']);\n",
        "\n",
        "plt.subplot(122)\n",
        "df['LoanAmount'].plot.box(figsize=(16,5))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNk4bn1bK-l7"
      },
      "source": [
        "**Question 5:** Do you notice any outliers?\n",
        "\n",
        "\n",
        "\n",
        "Analysis:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6:** Draw the same plots for the ApplicantIncome Feature and check if there are any outliers."
      ],
      "metadata": {
        "id": "FQYtbfc4sbee"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeyynE7mK-l7"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check if the gender affects the loan approval"
      ],
      "metadata": {
        "id": "1MaYv6qdqjaR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKEkDE5bK-mI"
      },
      "source": [
        "Gender=pd.crosstab(df['Gender'],df['Loan_Status'], normalize='index')\n",
        "print(Gender)\n",
        "Gender.plot(kind='bar', stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7:**\n",
        "\n",
        "a. Does gender affect loan approval?\n",
        "\n",
        "b. Suggest another method to study this relation"
      ],
      "metadata": {
        "id": "H1_LIotjssQS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVP8SFLlK-mK"
      },
      "source": [
        "Analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuiYEDpYK-mm"
      },
      "source": [
        "# 5. Preprocessing\n",
        "\"Garbage in, garbage out\".\n",
        "<br>\n",
        "<br>\n",
        "Data should be preprocessed and cleaned to get rid of noisy data. Preprocessing includes:\n",
        "\n",
        "- remove unsued column(s)\n",
        "- remove grabage data\n",
        "- convert continous data into categorical\n",
        "- treat missing data\n",
        "- encode categorical data\n",
        "- normalization: normalize data ranges for all features (e.g., between 0 and 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGumTAZLK-mm"
      },
      "source": [
        "## Remove unused columns\n",
        "Here we will drop some columns we beleive they do not affect the loan approval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw3LlHX1K-mn"
      },
      "source": [
        "df.drop(['Loan_ID','Gender','Self_Employed','ApplicantIncome','LoanAmount','Loan_Amount_Term'], inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBpOQ6MVK-mr"
      },
      "source": [
        "##Convert continous data into categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UATLaXcwK-ms"
      },
      "source": [
        "df['Credit_History'] = df['Credit_History'].astype('O')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpDPJgQzK-mu"
      },
      "source": [
        "## Treat missing data\n",
        "- fill missing categorical data & discrete data with mode\n",
        "- fill missing continous data with mean\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ifJSObwK-mv"
      },
      "source": [
        "df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)\n",
        "df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\n",
        "df['Married'].fillna(df['Married'].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x90s4TXqK-mx"
      },
      "source": [
        "## Check if any null value exist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8:** Write the code to check for any null values"
      ],
      "metadata": {
        "id": "kesbuF-htDWq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJi4rqkcK-mx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-aMmUFxK-m0"
      },
      "source": [
        "## Encode categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1emO7hK-m0"
      },
      "source": [
        "le = LabelEncoder()\n",
        "cat_data=df[['Credit_History','Dependents','Education','Married','Property_Area','Loan_Status']]\n",
        "num_data=df[['CoapplicantIncome']]\n",
        "cat_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwzdy2KjK-m2"
      },
      "source": [
        "for i in cat_data:\n",
        "    cat_data[i] = le.fit_transform(cat_data[i])\n",
        "cat_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1jU9d28K-m4"
      },
      "source": [
        "## Combine both cat_data and numerical_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dl3xeaLK-m5"
      },
      "source": [
        "df = pd.concat([cat_data, num_data], axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjg5n5OfK-m8"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luz-HezAucAx"
      },
      "source": [
        "**Question 9:** Normalize data ranges for all features (e.g., between 0 and 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b-_jm55K-m8"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW7e-IqSK-nA"
      },
      "source": [
        "# 6. Training & Validating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1R3upjnRVks"
      },
      "source": [
        "We split the data between training and testing.\n",
        "Then, we train a model to predict the loan status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfUvvKFTK-nA"
      },
      "source": [
        "input_variables = ['Credit_History','Dependents','Education','Married','Property_Area','CoapplicantIncome']\n",
        "x = df[input_variables]\n",
        "y = df['Loan_Status']\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size =0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIDedqKTtfN"
      },
      "source": [
        "##Creating & Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejo6DMwoSTbV"
      },
      "source": [
        "model=LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTy8UkrEUNLM"
      },
      "source": [
        "##Validating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFaCCnWUB2y"
      },
      "source": [
        "pred_val = model.predict(x_val)\n",
        "accuracy_score(y_val,pred_val)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}